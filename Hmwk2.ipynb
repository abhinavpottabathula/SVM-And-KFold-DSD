{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 DSD - Abhinav Pottabathula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import sklearn.svm as svm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('training.csv')\n",
    "train_x = train.drop(train.columns[[3]], axis=1)\n",
    "train_y = train.drop(train.columns[[0, 1, 2]], axis=1)\n",
    "\n",
    "tst = pd.read_csv('test.csv')\n",
    "tst_x = tst.drop(tst.columns[[3]], axis=1)\n",
    "tst_y = tst.drop(tst.columns[[0, 1, 2]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apottaba/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "train_grid, tst_grid = np.ndarray(shape=(5,4)), np.ndarray(shape=(5,4))\n",
    "C = [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "d = [1, 2, 3, 5]\n",
    "\n",
    "for c_pos in range(len(C)):\n",
    "    for d_pos in range(len(d)):\n",
    "        model = svm.SVC(C=C[c_pos], kernel='poly', degree=d[d_pos])\n",
    "        model.fit(train_x, train_y)\n",
    "        train_grid[c_pos][d_pos] = 1 - model.score(train_x, train_y)\n",
    "        tst_grid[c_pos][d_pos] = 1 - model.score(tst_x, tst_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.08908909  0.08908909  0.05105105  0.01801802]\n",
      " [ 0.08908909  0.08908909  0.02102102  0.01501502]\n",
      " [ 0.08808809  0.08908909  0.01801802  0.01701702]\n",
      " [ 0.03803804  0.08908909  0.01801802  0.01601602]\n",
      " [ 0.03403403  0.08908909  0.01701702  0.01601602]]\n",
      "[[ 0.44148049  0.44148049  0.12404135  0.09769923]\n",
      " [ 0.3717906   0.44148049  0.07835945  0.10003334]\n",
      " [ 0.18772924  0.44148049  0.0606869   0.10336779]\n",
      " [ 0.22074025  0.44148049  0.05635212  0.10103368]\n",
      " [ 0.23141047  0.44148049  0.05735245  0.10003334]]\n"
     ]
    }
   ],
   "source": [
    "print(train_grid)\n",
    "print(tst_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a1a1d1898>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAAD3CAYAAABYdBvmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEKlgIFLBQKSCgUgFA5EKBiIV/gvy7fUgH6iENwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a19eafa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a1a2ec0b8>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAAD3CAYAAABYdBvmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH+Ua6aidotgGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a19736828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(tst_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On what basis would you decide that a hyperparameter setting is optimal? Which setting of (C, d) gave the optimal results?\n",
    "\n",
    "I would decide a hyperparameter setting is optimal if it gives me a smaller error for both the training data and the testing data, and does not overfit to the training data. A very small error would mean overfitting to the training data. (.1, 3) gave the optimal results. The lowest test error was 0.05635212, and it had a training error of 0.01801802, so it had a good balance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’ll notice that between C and d, one factor mattered far more than the other. What can you conclude about the structure of the datasets and how they were generated?\n",
    "\n",
    "d is more important than C.\n",
    "\n",
    "As C increases the model will classify training data more accurately with smaller-margin hyperplanes. Thus the optimal value of C is when it is in the middle of the range [0.0001, 0.001, 0.01, 0.1,1]. Small hyperplanes are important, but when they become too small it leads to overfitting. \n",
    "\n",
    "d has a strong impact on the error, because the data best fits a certain kernel type and degree. Out of all the polynomial degrees we were asked to try, the best was d=3. \n",
    "\n",
    "In conclusion, I believe the best combination of hyperparameters matches with the hypothesis that the data was generated with some noise because the C has to be optimized in terms of its sensitivity to noise and when creating the hyper-planes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With as much granularity as possible, which hyperparameter settings are underfitting and which are overfitting? What allows you to make this claim?\n",
    "\n",
    "The hyperparameters that are overfitting is when both C and d are really high (C=1 and/or d=5). Both their effect on the training data and the testing error is usually higher, which is characteristic of overfitting. This is also intuitive because as C increases, the classifier becomes more sensitive to noise and as d increases the kernel will become increasingly unique when drawing the boundary for the training data. With this increase, the model will strongly match the training data, but not so much the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apottaba/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gamma</th>\n",
       "      <th>Validation Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.089122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.046038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.034036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.045039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.086118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.089122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000.000</td>\n",
       "      <td>0.089122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gamma  Validation Error\n",
       "0     0.001          0.089122\n",
       "1     0.010          0.046038\n",
       "2     0.100          0.034036\n",
       "3     1.000          0.045039\n",
       "4    10.000          0.086118\n",
       "5   100.000          0.089122\n",
       "6  1000.000          0.089122"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "g_vals = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "val_error = []\n",
    "\n",
    "train_x_np = np.array(train_x)\n",
    "train_y_np = np.array(train_y)\n",
    "\n",
    "for gamma_i in range(len(g_vals)):\n",
    "    model = svm.SVC(C=1, kernel='rbf', gamma=g_vals[gamma_i])\n",
    "    kfold = KFold(999, n_folds=7)\n",
    "    total_error = 0\n",
    "    \n",
    "    for train_i, test_i in kfold:\n",
    "        tr_x, tr_y = train_x_np[train_i], train_y_np[train_i]\n",
    "        ts_x, ts_y = train_x_np[test_i], train_y_np[test_i]\n",
    "        model.fit(tr_x, tr_y)\n",
    "        total_error += 1 - model.score(ts_x, ts_y)\n",
    "    \n",
    "    val_error.append(total_error/7)\n",
    "    \n",
    "df = pd.DataFrame(data = {'Gamma':g_vals, 'Validation Error':val_error})\n",
    "df "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
